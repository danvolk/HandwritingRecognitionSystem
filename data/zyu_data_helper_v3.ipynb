{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZYu Data Helper v3\n",
    "\n",
    "1.\tThe notebook reads “lines_copy.txt” into a dataframe (df), df has all the information about every image in the IAM lines dataset.\n",
    "\n",
    "2.\tThe notebook builds a tokenizer (here it uses keras) using the CHARLIST file, the tokenizer maps each character to a number between 0-189.\n",
    "\n",
    "3.\tThe notebook then uses the tokenizer to convert text into a string of numbers, for example: `\" and he is to be backed by Mr. Will \"`  will become  `\"0 62 75 … 73 73 0\"`\n",
    "\n",
    "4.\tThe tokenized string is added back to the df.\n",
    "\n",
    "5.\tYou choose a subset from df, this new dataframe is called df_data, this defines the data you are going to use.\n",
    "\n",
    "6.\tYou split df_data into  df_train, df_val, df_test\n",
    "\n",
    "7.\tBased on the information in df_train, df_val, df_test, the notebook first cleans up the destination folders, then it copies files (original and deslanted) from source (i.e. HRS/data/lines and HRS/data/lines_deslanted) to destination folders (i.e. HRS/data/train etc.), and creates label files etc. in these folders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a01-000u-00 ok 154 19 408 746 1661 89 A|MOVE|to|stop|Mr.|Gaitskell|from\n",
      "a01-000u-01 ok 156 19 395 932 1850 105 nominating|any|more|Labour|life|Peers\n",
      "a01-000u-02 ok 157 16 408 1106 1986 105 is|to|be|made|at|a|meeting|of|Labour\n",
      "a01-000u-03 err 156 23 430 1290 1883 70 M Ps|tomorrow|.|Mr.|Michael|Foot|has\n",
      "a01-000u-04 ok 157 20 395 1474 1830 94 put|down|a|resolution|on|the|subject\n",
      "a01-000u-05 err 156 21 379 1643 1854 88 and|he|is|to|be|backed|by|Mr.|Will\n",
      "a01-000u-06 ok 159 20 363 1825 2051 87 Griffiths|,|M P|for|Manchester|Exchange|.\n",
      "a01-000x-00 ok 182 30 375 748 1561 148 A|MOVE|to|stop|Mr.|Gaitskell|from|nominating\n",
      "a01-000x-01 ok 181 23 382 924 1595 148 any|more|Labour|life|Peers|is|to|be|made|at|a\n",
      "a01-000x-02 ok 181 30 386 1110 1637 140 meeting|of|Labour|0M Ps|tomorrow|.|Mr.|Michael\n"
     ]
    }
   ],
   "source": [
    "# take a look at lines_copy.txt\n",
    "!head lines/lines_copy.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read meta-data into a dataframe\n",
    "\n",
    "\n",
    "### NOTE: ADDED SPACE TO BEGINNING AND END OF TEXT\n",
    "\n",
    "add \"space\" to the beginning and end of the text for the tokenizing purpose, because in \"HandwritingRecognition\", the ground truth starts and ends with \"0\", which is \"space\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read information about the IAM lines from `lines_copy.txt` into dataframe `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>wseg_status</th>\n",
       "      <th>graylevel</th>\n",
       "      <th>num_components</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a01-000u-00</td>\n",
       "      <td>ok</td>\n",
       "      <td>154</td>\n",
       "      <td>19</td>\n",
       "      <td>408</td>\n",
       "      <td>746</td>\n",
       "      <td>1661</td>\n",
       "      <td>89</td>\n",
       "      <td>A MOVE to stop Mr. Gaitskell from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a01-000u-01</td>\n",
       "      <td>ok</td>\n",
       "      <td>156</td>\n",
       "      <td>19</td>\n",
       "      <td>395</td>\n",
       "      <td>932</td>\n",
       "      <td>1850</td>\n",
       "      <td>105</td>\n",
       "      <td>nominating any more Labour life Peers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a01-000u-02</td>\n",
       "      <td>ok</td>\n",
       "      <td>157</td>\n",
       "      <td>16</td>\n",
       "      <td>408</td>\n",
       "      <td>1106</td>\n",
       "      <td>1986</td>\n",
       "      <td>105</td>\n",
       "      <td>is to be made at a meeting of Labour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a01-000u-03</td>\n",
       "      <td>err</td>\n",
       "      <td>156</td>\n",
       "      <td>23</td>\n",
       "      <td>430</td>\n",
       "      <td>1290</td>\n",
       "      <td>1883</td>\n",
       "      <td>70</td>\n",
       "      <td>M Ps tomorrow . Mr. Michael Foot has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a01-000u-04</td>\n",
       "      <td>ok</td>\n",
       "      <td>157</td>\n",
       "      <td>20</td>\n",
       "      <td>395</td>\n",
       "      <td>1474</td>\n",
       "      <td>1830</td>\n",
       "      <td>94</td>\n",
       "      <td>put down a resolution on the subject</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id wseg_status  graylevel  num_components    x     y     w    h  \\\n",
       "0  a01-000u-00          ok        154              19  408   746  1661   89   \n",
       "1  a01-000u-01          ok        156              19  395   932  1850  105   \n",
       "2  a01-000u-02          ok        157              16  408  1106  1986  105   \n",
       "3  a01-000u-03         err        156              23  430  1290  1883   70   \n",
       "4  a01-000u-04          ok        157              20  395  1474  1830   94   \n",
       "\n",
       "                                     label  \n",
       "0       A MOVE to stop Mr. Gaitskell from   \n",
       "1   nominating any more Labour life Peers   \n",
       "2    is to be made at a meeting of Labour   \n",
       "3    M Ps tomorrow . Mr. Michael Foot has   \n",
       "4    put down a resolution on the subject   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_in = 'lines/lines_copy.txt'\n",
    "\n",
    "fhand = open(file_in)\n",
    "data_list = [] \n",
    "\n",
    "for line in fhand:\n",
    "    item = line.split(\" \")   # split the line\n",
    "    num = len(item)          # number of fields if line delimited by \" \"\n",
    "    \n",
    "    if num == 9:             # good lines\n",
    "        label = item[8]      # last field is label if only 9 field\n",
    "    else:                    # bad lines with spaces in \"label\"\n",
    "        label = \" \".join(item[8:])    # join the remaining fields - this is label\n",
    "\n",
    "    new_data  ={'id': item[0], \n",
    "                'wseg_status': item[1], \n",
    "                'graylevel': int(item[2]), \n",
    "                'num_components': int(item[3]), \n",
    "                'x': int(item[4]), \n",
    "                'y': int(item[5]), \n",
    "                'w': int(item[6]), \n",
    "                'h': int(item[7]), \n",
    "                'label': \" \"+label.rstrip().replace(\"|\", \" \")+\" \"}   # remove \"\\n\", replace \"|\" with \" \"\n",
    "    \n",
    "    data_list.append(new_data)\n",
    "    \n",
    "fhand.close()\n",
    "\n",
    "df = pd.DataFrame(data_list, \n",
    "                  columns=['id', 'wseg_status', 'graylevel', 'num_components', 'x', 'y', 'w', 'h', 'label'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build a tokenizer using `CHAR_LIST`\n",
    "\n",
    "NOTE: this adds 0 to the beginning and end of string based on the convention in \"HandwritingRecognitionSystem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 190 511 CHAR_LIST\n"
     ]
    }
   ],
   "source": [
    "# There are 190 characters in CHAR_LIST\n",
    "!wc CHAR_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SPACE>\n",
      "<UNK>\n",
      "!\n",
      "\"\n",
      "#\n",
      "$\n",
      "%\n",
      "&\n",
      "'\n",
      "(\n"
     ]
    }
   ],
   "source": [
    "# take a look at CHAR_LIST\n",
    "!head CHAR_LIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a tokenizer that converts characters to numbers\n",
    "\n",
    "Here we borrow the \"Tokenizer\" class from keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SPACE><UNK>!\"#$%&'()*+,-./0123456789:;=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz|~£§¨«¬­°²´·º»¼½¾ÀÂÄÇÈÉÊÔÖÜßàáâäæçèéêëìîïñòóôöøùúûüÿłŒœΓΖΤάήαδεηικλμνξοπρτυχψωόώІ–—†‡‰‹›₂₤℔⅓⅔⅕⅗⅘⅛∫≠□✓ｆ\n",
      "190\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=190, char_level=True, lower=False)  # NOT TO COVERT TO LOWER CASE\n",
    "\n",
    "file_in = 'CHAR_LIST'\n",
    "\n",
    "fhand = open(file_in)\n",
    "\n",
    "chars = {}\n",
    "\n",
    "num = 0\n",
    "for line in fhand:\n",
    "    char = line.rstrip()\n",
    "    chars[char]=num\n",
    "    print(line.rstrip(), end=\"\")\n",
    "    num += 1\n",
    "fhand.close()\n",
    "\n",
    "print()\n",
    "print(num)\n",
    "\n",
    "chars[' ']=0   # encode <space> as 0\n",
    "tokenizer.word_index = chars    # set word_map for tokenizer\n",
    "tokenizer.oov_token=1           # encode <UNK> character as 1\n",
    "\n",
    "reverse_word_map = dict(map(reversed, chars.items()))   \n",
    "\n",
    "def sequence_to_string(list_of_numbers):\n",
    "    list_of_num_strings = list(map(str, list_of_numbers))  # Turn list of numbers to list of strings\n",
    "    string_of_numbers = ' '.join(list_of_num_strings)      # Join into one string\n",
    "    return string_of_numbers\n",
    "\n",
    "def sequence_to_text(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    text = ''.join(words)    \n",
    "    return text\n",
    "\n",
    "def tokenized_string_to_text(tokenized_string):\n",
    "    token_strings = tokenized_string.split(\" \")\n",
    "    tokens = [int(token_string) for token_string in token_strings]\n",
    "    words = [reverse_word_map.get(letter) for letter in tokens]\n",
    "    text = ''.join(words)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Turn texts into tokenized strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = list(df['label'])\n",
    "sequences_of_texts = tokenizer.texts_to_sequences(texts) \n",
    "tokenized_strings = list(map(sequence_to_string, sequences_of_texts))\n",
    "\n",
    "texts_back = list(map(tokenized_string_to_text, tokenized_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' A MOVE to stop Mr. Gaitskell from ',\n",
       " ' nominating any more Labour life Peers ',\n",
       " ' is to be made at a meeting of Labour ',\n",
       " ' M Ps tomorrow . Mr. Michael Foot has ',\n",
       " ' put down a resolution on the subject ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at text\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 32, 0, 44, 46, 53, 36, 0, 81, 76, 0, 80, 81, 76, 77, 0, 44, 79, 15, 0, 38, 62, 70, 81, 80, 72, 66, 73, 73, 0, 67, 79, 76, 74, 0], [0, 75, 76, 74, 70, 75, 62, 81, 70, 75, 68, 0, 62, 75, 86, 0, 74, 76, 79, 66, 0, 43, 62, 63, 76, 82, 79, 0, 73, 70, 67, 66, 0, 47, 66, 66, 79, 80, 0], [0, 70, 80, 0, 81, 76, 0, 63, 66, 0, 74, 62, 65, 66, 0, 62, 81, 0, 62, 0, 74, 66, 66, 81, 70, 75, 68, 0, 76, 67, 0, 43, 62, 63, 76, 82, 79, 0], [0, 44, 0, 47, 80, 0, 81, 76, 74, 76, 79, 79, 76, 84, 0, 15, 0, 44, 79, 15, 0, 44, 70, 64, 69, 62, 66, 73, 0, 37, 76, 76, 81, 0, 69, 62, 80, 0], [0, 77, 82, 81, 0, 65, 76, 84, 75, 0, 62, 0, 79, 66, 80, 76, 73, 82, 81, 70, 76, 75, 0, 76, 75, 0, 81, 69, 66, 0, 80, 82, 63, 71, 66, 64, 81, 0]]\n"
     ]
    }
   ],
   "source": [
    "# take a look at tokens\n",
    "print(sequences_of_texts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 32 0 44 46 53 36 0 81 76 0 80 81 76 77 0 44 79 15 0 38 62 70 81 80 72 66 73 73 0 67 79 76 74 0',\n",
       " '0 75 76 74 70 75 62 81 70 75 68 0 62 75 86 0 74 76 79 66 0 43 62 63 76 82 79 0 73 70 67 66 0 47 66 66 79 80 0',\n",
       " '0 70 80 0 81 76 0 63 66 0 74 62 65 66 0 62 81 0 62 0 74 66 66 81 70 75 68 0 76 67 0 43 62 63 76 82 79 0',\n",
       " '0 44 0 47 80 0 81 76 74 76 79 79 76 84 0 15 0 44 79 15 0 44 70 64 69 62 66 73 0 37 76 76 81 0 69 62 80 0',\n",
       " '0 77 82 81 0 65 76 84 75 0 62 0 79 66 80 76 73 82 81 70 76 75 0 76 75 0 81 69 66 0 80 82 63 71 66 64 81 0']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at tokenized strings, this is the \"ground truth\" used in HRS\n",
    "tokenized_strings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' A MOVE to stop Mr. Gaitskell from ',\n",
       " ' nominating any more Labour life Peers ',\n",
       " ' is to be made at a meeting of Labour ',\n",
       " ' M Ps tomorrow . Mr. Michael Foot has ',\n",
       " ' put down a resolution on the subject ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure we can convert to tokenized_string back to the original text\n",
    "texts_back[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Add tokenized strings back to the dataframe\n",
    "\n",
    "There are **13353** images inth `lines` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>wseg_status</th>\n",
       "      <th>graylevel</th>\n",
       "      <th>num_components</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>label</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a01-000u-00</td>\n",
       "      <td>ok</td>\n",
       "      <td>154</td>\n",
       "      <td>19</td>\n",
       "      <td>408</td>\n",
       "      <td>746</td>\n",
       "      <td>1661</td>\n",
       "      <td>89</td>\n",
       "      <td>A MOVE to stop Mr. Gaitskell from</td>\n",
       "      <td>0 32 0 44 46 53 36 0 81 76 0 80 81 76 77 0 44 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a01-000u-01</td>\n",
       "      <td>ok</td>\n",
       "      <td>156</td>\n",
       "      <td>19</td>\n",
       "      <td>395</td>\n",
       "      <td>932</td>\n",
       "      <td>1850</td>\n",
       "      <td>105</td>\n",
       "      <td>nominating any more Labour life Peers</td>\n",
       "      <td>0 75 76 74 70 75 62 81 70 75 68 0 62 75 86 0 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a01-000u-02</td>\n",
       "      <td>ok</td>\n",
       "      <td>157</td>\n",
       "      <td>16</td>\n",
       "      <td>408</td>\n",
       "      <td>1106</td>\n",
       "      <td>1986</td>\n",
       "      <td>105</td>\n",
       "      <td>is to be made at a meeting of Labour</td>\n",
       "      <td>0 70 80 0 81 76 0 63 66 0 74 62 65 66 0 62 81 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a01-000u-03</td>\n",
       "      <td>err</td>\n",
       "      <td>156</td>\n",
       "      <td>23</td>\n",
       "      <td>430</td>\n",
       "      <td>1290</td>\n",
       "      <td>1883</td>\n",
       "      <td>70</td>\n",
       "      <td>M Ps tomorrow . Mr. Michael Foot has</td>\n",
       "      <td>0 44 0 47 80 0 81 76 74 76 79 79 76 84 0 15 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a01-000u-04</td>\n",
       "      <td>ok</td>\n",
       "      <td>157</td>\n",
       "      <td>20</td>\n",
       "      <td>395</td>\n",
       "      <td>1474</td>\n",
       "      <td>1830</td>\n",
       "      <td>94</td>\n",
       "      <td>put down a resolution on the subject</td>\n",
       "      <td>0 77 82 81 0 65 76 84 75 0 62 0 79 66 80 76 73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a01-000u-05</td>\n",
       "      <td>err</td>\n",
       "      <td>156</td>\n",
       "      <td>21</td>\n",
       "      <td>379</td>\n",
       "      <td>1643</td>\n",
       "      <td>1854</td>\n",
       "      <td>88</td>\n",
       "      <td>and he is to be backed by Mr. Will</td>\n",
       "      <td>0 62 75 65 0 69 66 0 70 80 0 81 76 0 63 66 0 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a01-000u-06</td>\n",
       "      <td>ok</td>\n",
       "      <td>159</td>\n",
       "      <td>20</td>\n",
       "      <td>363</td>\n",
       "      <td>1825</td>\n",
       "      <td>2051</td>\n",
       "      <td>87</td>\n",
       "      <td>Griffiths , M P for Manchester Exchange .</td>\n",
       "      <td>0 38 79 70 67 67 70 81 69 80 0 13 0 44 0 47 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a01-000x-00</td>\n",
       "      <td>ok</td>\n",
       "      <td>182</td>\n",
       "      <td>30</td>\n",
       "      <td>375</td>\n",
       "      <td>748</td>\n",
       "      <td>1561</td>\n",
       "      <td>148</td>\n",
       "      <td>A MOVE to stop Mr. Gaitskell from nominating</td>\n",
       "      <td>0 32 0 44 46 53 36 0 81 76 0 80 81 76 77 0 44 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a01-000x-01</td>\n",
       "      <td>ok</td>\n",
       "      <td>181</td>\n",
       "      <td>23</td>\n",
       "      <td>382</td>\n",
       "      <td>924</td>\n",
       "      <td>1595</td>\n",
       "      <td>148</td>\n",
       "      <td>any more Labour life Peers is to be made at a</td>\n",
       "      <td>0 62 75 86 0 74 76 79 66 0 43 62 63 76 82 79 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a01-000x-02</td>\n",
       "      <td>ok</td>\n",
       "      <td>181</td>\n",
       "      <td>30</td>\n",
       "      <td>386</td>\n",
       "      <td>1110</td>\n",
       "      <td>1637</td>\n",
       "      <td>140</td>\n",
       "      <td>meeting of Labour 0M Ps tomorrow . Mr. Michael</td>\n",
       "      <td>0 74 66 66 81 70 75 68 0 76 67 0 43 62 63 76 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id wseg_status  graylevel  num_components    x     y     w    h  \\\n",
       "0  a01-000u-00          ok        154              19  408   746  1661   89   \n",
       "1  a01-000u-01          ok        156              19  395   932  1850  105   \n",
       "2  a01-000u-02          ok        157              16  408  1106  1986  105   \n",
       "3  a01-000u-03         err        156              23  430  1290  1883   70   \n",
       "4  a01-000u-04          ok        157              20  395  1474  1830   94   \n",
       "5  a01-000u-05         err        156              21  379  1643  1854   88   \n",
       "6  a01-000u-06          ok        159              20  363  1825  2051   87   \n",
       "7  a01-000x-00          ok        182              30  375   748  1561  148   \n",
       "8  a01-000x-01          ok        181              23  382   924  1595  148   \n",
       "9  a01-000x-02          ok        181              30  386  1110  1637  140   \n",
       "\n",
       "                                              label  \\\n",
       "0                A MOVE to stop Mr. Gaitskell from    \n",
       "1            nominating any more Labour life Peers    \n",
       "2             is to be made at a meeting of Labour    \n",
       "3             M Ps tomorrow . Mr. Michael Foot has    \n",
       "4             put down a resolution on the subject    \n",
       "5               and he is to be backed by Mr. Will    \n",
       "6        Griffiths , M P for Manchester Exchange .    \n",
       "7     A MOVE to stop Mr. Gaitskell from nominating    \n",
       "8    any more Labour life Peers is to be made at a    \n",
       "9   meeting of Labour 0M Ps tomorrow . Mr. Michael    \n",
       "\n",
       "                                               truth  \n",
       "0  0 32 0 44 46 53 36 0 81 76 0 80 81 76 77 0 44 ...  \n",
       "1  0 75 76 74 70 75 62 81 70 75 68 0 62 75 86 0 7...  \n",
       "2  0 70 80 0 81 76 0 63 66 0 74 62 65 66 0 62 81 ...  \n",
       "3  0 44 0 47 80 0 81 76 74 76 79 79 76 84 0 15 0 ...  \n",
       "4  0 77 82 81 0 65 76 84 75 0 62 0 79 66 80 76 73...  \n",
       "5  0 62 75 65 0 69 66 0 70 80 0 81 76 0 63 66 0 6...  \n",
       "6  0 38 79 70 67 67 70 81 69 80 0 13 0 44 0 47 0 ...  \n",
       "7  0 32 0 44 46 53 36 0 81 76 0 80 81 76 77 0 44 ...  \n",
       "8  0 62 75 86 0 74 76 79 66 0 43 62 63 76 82 79 0...  \n",
       "9  0 74 66 66 81 70 75 68 0 76 67 0 43 62 63 76 8...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['truth'] = tokenized_strings\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Select a subset of files\n",
    "\n",
    "You can choose a subset of \"df\" as \"data_df\" for training/testing your model.\n",
    "\n",
    "Here we set **data_df=df**, that means we are going to copy all files.\n",
    "\n",
    "We also split the data into train/val/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select data to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## If you only want to use a randomly selected subset of data ####################\n",
    "#data_size=10000\n",
    "#df_data = df.sample(n=data_size, replace=False, axis=0, random_state=8)\n",
    "\n",
    "## If you want to copy all the data ##############################################\n",
    "df_data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the selected data into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(df, val_size=0.1, test_size=0.1, random_seed=8):\n",
    "    # create shuffled index\n",
    "    # seed rest every time the function is called, index of same length will be cut the same way \n",
    "    indices = np.arange(df.shape[0])\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    # shuffle the data\n",
    "    df = df.iloc[indices,:]\n",
    "    \n",
    "    # cut position for train and validation\n",
    "    train_cut = round(df.shape[0] * (1 - test_size - val_size))     \n",
    "    val_cut = round(df.shape[0] * (1 - test_size))  \n",
    "    \n",
    "    # split the data into train, val, test\n",
    "    train_df = df.iloc[:train_cut,:]\n",
    "    val_df = df.iloc[train_cut:val_cut,:]\n",
    "    test_df = df.iloc[val_cut:,:]\n",
    "    \n",
    "    return train_df, val_df, test_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10682\n",
      "1336\n",
      "1335\n"
     ]
    }
   ],
   "source": [
    "# call the function to split the data\n",
    "df_train, df_val, df_test = train_val_test_split(df_data, val_size=0.1, test_size=0.1, random_seed=8)\n",
    "\n",
    "print(df_train.shape[0])\n",
    "print(df_val.shape[0])\n",
    "print(df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>wseg_status</th>\n",
       "      <th>graylevel</th>\n",
       "      <th>num_components</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>label</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>c04-056-01</td>\n",
       "      <td>ok</td>\n",
       "      <td>167</td>\n",
       "      <td>31</td>\n",
       "      <td>333</td>\n",
       "      <td>933</td>\n",
       "      <td>1873</td>\n",
       "      <td>113</td>\n",
       "      <td>comics bolted in and out of holes so often .</td>\n",
       "      <td>0 64 76 74 70 64 80 0 63 76 73 81 66 65 0 70 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>g02-062-05</td>\n",
       "      <td>ok</td>\n",
       "      <td>152</td>\n",
       "      <td>48</td>\n",
       "      <td>304</td>\n",
       "      <td>1841</td>\n",
       "      <td>1687</td>\n",
       "      <td>108</td>\n",
       "      <td>the dissections of living animals , Harvey no...</td>\n",
       "      <td>0 81 69 66 0 65 70 80 80 66 64 81 70 76 75 80 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>b01-118-05</td>\n",
       "      <td>ok</td>\n",
       "      <td>162</td>\n",
       "      <td>18</td>\n",
       "      <td>327</td>\n",
       "      <td>1631</td>\n",
       "      <td>1800</td>\n",
       "      <td>124</td>\n",
       "      <td>Hitler in the thirties . It was Dr. Verwoerd ...</td>\n",
       "      <td>0 39 70 81 73 66 79 0 70 75 0 81 69 66 0 81 69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>c06-091-04</td>\n",
       "      <td>err</td>\n",
       "      <td>181</td>\n",
       "      <td>32</td>\n",
       "      <td>320</td>\n",
       "      <td>1403</td>\n",
       "      <td>1867</td>\n",
       "      <td>205</td>\n",
       "      <td>Gina , walking out on the man who has so far</td>\n",
       "      <td>0 38 70 75 62 0 13 0 84 62 73 72 70 75 68 0 76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>h04-082-07</td>\n",
       "      <td>err</td>\n",
       "      <td>179</td>\n",
       "      <td>49</td>\n",
       "      <td>386</td>\n",
       "      <td>1659</td>\n",
       "      <td>1768</td>\n",
       "      <td>100</td>\n",
       "      <td>poultry , eggs , canned vegetables , fresh fr...</td>\n",
       "      <td>0 77 76 82 73 81 79 86 0 13 0 66 68 68 80 0 13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id wseg_status  graylevel  num_components    x     y     w    h  \\\n",
       "3633  c04-056-01          ok        167              31  333   933  1873  113   \n",
       "6489  g02-062-05          ok        152              48  304  1841  1687  108   \n",
       "2031  b01-118-05          ok        162              18  327  1631  1800  124   \n",
       "3918  c06-091-04         err        181              32  320  1403  1867  205   \n",
       "8728  h04-082-07         err        179              49  386  1659  1768  100   \n",
       "\n",
       "                                                  label  \\\n",
       "3633      comics bolted in and out of holes so often .    \n",
       "6489   the dissections of living animals , Harvey no...   \n",
       "2031   Hitler in the thirties . It was Dr. Verwoerd ...   \n",
       "3918      Gina , walking out on the man who has so far    \n",
       "8728   poultry , eggs , canned vegetables , fresh fr...   \n",
       "\n",
       "                                                  truth  \n",
       "3633  0 64 76 74 70 64 80 0 63 76 73 81 66 65 0 70 7...  \n",
       "6489  0 81 69 66 0 65 70 80 80 66 64 81 70 76 75 80 ...  \n",
       "2031  0 39 70 81 73 66 79 0 70 75 0 81 69 66 0 81 69...  \n",
       "3918  0 38 70 75 62 0 13 0 84 62 73 72 70 75 68 0 76...  \n",
       "8728  0 77 76 82 73 81 79 86 0 13 0 66 68 68 80 0 13...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create folders for train, val, test\n",
    "\n",
    "Also add folders for deslanted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/HRS/data\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For original IAM data\n",
    "!mkdir -p train/Images train/Labels train/Text\n",
    "!mkdir -p val/Images val/Labels val/Text\n",
    "!mkdir -p test/Images test/Labels test/Text\n",
    "\n",
    "# For deslanted IAM data\n",
    "!mkdir -p train_deslanted/Images train_deslanted/Labels train_deslanted/Text\n",
    "!mkdir -p val_deslanted/Images val_deslanted/Labels val_deslanted/Text\n",
    "!mkdir -p test_deslanted/Images test_deslanted/Labels test_deslanted/Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAR_LIST\t test\t\t train_deslanted  zyu_data_helper_v3.ipynb\n",
      "lines\t\t test_deslanted  val\n",
      "lines_deslanted  train\t\t val_deslanted\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Copy selected files to destination\n",
    "\n",
    "For example, the first line:\n",
    "\n",
    "- source: `./lines/a03/a03-066/a03-066-01.png`\n",
    "\n",
    "- destination: `./train/Images/a03-066-01.png`\n",
    "\n",
    "\n",
    "Work flow:\n",
    "\n",
    "- initialize `file_list={}`\n",
    "\n",
    "- loop through each line in the data frame\n",
    "\n",
    "- use `id` field to create `source` and `destination`, `label_file_name`, `text_file_name`\n",
    "\n",
    "- use `label` to create `*.txt` file\n",
    "\n",
    "- use `truth` to create `*.tru` file\n",
    "\n",
    "- copy `source` to `destination`\n",
    "\n",
    "- ads id to `list`\n",
    "\n",
    "- create `./train/list`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_folder(destination_dir):\n",
    "    \"\"\"\n",
    "    only delete files and to used the os.path.join() method  \n",
    "    If you also want to remove subdirectories, uncomment the elif statement.\n",
    "    \"\"\"\n",
    "    \n",
    "    import os, shutil\n",
    "    folder = destination_dir\n",
    "    \n",
    "    count = 0\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "                count += 1\n",
    "            #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    print(\"Successfully removed\", count, \"files from\", destination_dir)  \n",
    "    \n",
    "    \n",
    "def prepare_data_files(df, source_dir, destination_dir):\n",
    "    \"\"\"Copy original png to destination and create label, txt, list files\"\"\"\n",
    "    destination_images_dir = destination_dir + '/Images'\n",
    "    destination_labels_dir = destination_dir + '/Labels'\n",
    "    destination_text_dir = destination_dir + '/Text'\n",
    "    destination_list_file = destination_dir + '/list'\n",
    "    \n",
    "    clean_folder(destination_dir)\n",
    "    clean_folder(destination_images_dir)\n",
    "    clean_folder(destination_labels_dir)\n",
    "    clean_folder(destination_text_dir)\n",
    "    \n",
    "    from shutil import copy2\n",
    "\n",
    "    lines_list = []\n",
    "\n",
    "    for i in range(df.shape[0]):    \n",
    "\n",
    "        # read data from each row\n",
    "        img_data = df.iloc[i]            # each line in dataframe\n",
    "\n",
    "        img_id = img_data['id']         # data for file\n",
    "        img_file = img_id + '.png'      # img file_name\n",
    "        label_file = img_id + '.tru'    # label file_name\n",
    "        text_file = img_id + '.txt'     # text file_name\n",
    "\n",
    "        img_text = img_data['label']    # img text\n",
    "        img_truth = img_data['truth']   # img ground truth (tokenized string) \n",
    "\n",
    "        # create source and destination file names\n",
    "        id_pc = img_id.split(\"-\")\n",
    "        source_img_file = source_dir + \"/\" +id_pc[0] + \"/\" + id_pc[0] + \"-\" + id_pc[1] + \"/\" + img_file\n",
    "        destination_img_file = destination_images_dir  + \"/\" + img_file\n",
    "\n",
    "        destination_label_file = destination_labels_dir + \"/\" + label_file\n",
    "        destination_text_file = destination_text_dir + \"/\" + text_file\n",
    "        destination_list_file = destination_list_file\n",
    "\n",
    "        lines_list.append(img_id)\n",
    "\n",
    "        # copy source to destination\n",
    "        copy2(source_img_file, destination_img_file)\n",
    "\n",
    "        # write label file (ground truth)\n",
    "        f_label = open(destination_label_file, \"w\")\n",
    "        f_label.write(img_truth)\n",
    "        f_label.close()    \n",
    "\n",
    "        # write text file (img text)\n",
    "        f_text = open(destination_text_file, \"w\")\n",
    "        f_text.write(img_text)\n",
    "        f_text.close()\n",
    "\n",
    "    # write list file\n",
    "    with open(destination_list_file, 'a') as fout:\n",
    "        for line in lines_list:\n",
    "            fout.write(line + \"\\n\")\n",
    "\n",
    "def prepare_deslanted_data_files(df, source_dir, destination_dir):\n",
    "    \"\"\"Copy deslanted png to destination and create label, txt, list files\"\"\"\n",
    "    destination_images_dir = destination_dir + '/Images'\n",
    "    destination_labels_dir = destination_dir + '/Labels'\n",
    "    destination_text_dir = destination_dir + '/Text'\n",
    "    destination_list_file = destination_dir + '/list'\n",
    "    \n",
    "    clean_folder(destination_dir)\n",
    "    clean_folder(destination_images_dir)\n",
    "    clean_folder(destination_labels_dir)\n",
    "    clean_folder(destination_text_dir)\n",
    "    \n",
    "    from shutil import copy2\n",
    "\n",
    "    lines_list = []\n",
    "\n",
    "    for i in range(df.shape[0]):    \n",
    "\n",
    "        # read data from each row\n",
    "        img_data = df.iloc[i]            # each line in dataframe\n",
    "\n",
    "        img_id = img_data['id']         # data for file\n",
    "        img_file = img_id + '.png'      # img file_name\n",
    "        label_file = img_id + '.tru'    # label file_name\n",
    "        text_file = img_id + '.txt'     # text file_name\n",
    "\n",
    "        img_text = img_data['label']    # img text\n",
    "        img_truth = img_data['truth']   # img ground truth (tokenized string) \n",
    "\n",
    "        # create source and destination file names\n",
    "        id_pc = img_id.split(\"-\")\n",
    "        source_img_file = source_dir + \"/\" + img_file\n",
    "        destination_img_file = destination_images_dir  + \"/\" + img_file\n",
    "\n",
    "        destination_label_file = destination_labels_dir + \"/\" + label_file\n",
    "        destination_text_file = destination_text_dir + \"/\" + text_file\n",
    "        destination_list_file = destination_list_file\n",
    "\n",
    "        lines_list.append(img_id)\n",
    "\n",
    "        # copy source to destination\n",
    "        copy2(source_img_file, destination_img_file)\n",
    "\n",
    "        # write label file (ground truth)\n",
    "        f_label = open(destination_label_file, \"w\")\n",
    "        f_label.write(img_truth)\n",
    "        f_label.close()    \n",
    "\n",
    "        # write text file (img text)\n",
    "        f_text = open(destination_text_file, \"w\")\n",
    "        f_text.write(img_text)\n",
    "        f_text.close()\n",
    "\n",
    "    # write list file\n",
    "    with open(destination_list_file, 'a') as fout:\n",
    "        for line in lines_list:\n",
    "            fout.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define source and destination folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directories for the original IAM data\n",
    "source_dir = './lines'\n",
    "train_destination_dir = './train'\n",
    "val_destination_dir = './val'\n",
    "test_destination_dir = './test'\n",
    "\n",
    "# directories for the deslanted IAM data\n",
    "source_dir_deslanted = './lines_deslanted'\n",
    "train_destination_dir_deslanted = './train_deslanted'\n",
    "val_destination_dir_deslanted = './val_deslanted'\n",
    "test_destination_dir_deslanted = './test_deslanted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the \"original\" IAM lines data to destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully removed 0 files from ./train\n",
      "Successfully removed 0 files from ./train/Images\n",
      "Successfully removed 0 files from ./train/Labels\n",
      "Successfully removed 0 files from ./train/Text\n",
      "Successfully removed 0 files from ./val\n",
      "Successfully removed 0 files from ./val/Images\n",
      "Successfully removed 0 files from ./val/Labels\n",
      "Successfully removed 0 files from ./val/Text\n",
      "Successfully removed 0 files from ./test\n",
      "Successfully removed 0 files from ./test/Images\n",
      "Successfully removed 0 files from ./test/Labels\n",
      "Successfully removed 0 files from ./test/Text\n"
     ]
    }
   ],
   "source": [
    "prepare_data_files(df_train, source_dir, train_destination_dir)\n",
    "prepare_data_files(df_val, source_dir, val_destination_dir)\n",
    "prepare_data_files(df_test, source_dir, test_destination_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the \"deslanted\" IAM lines data to destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully removed 0 files from ./train_deslanted\n",
      "Successfully removed 0 files from ./train_deslanted/Images\n",
      "Successfully removed 0 files from ./train_deslanted/Labels\n",
      "Successfully removed 0 files from ./train_deslanted/Text\n",
      "Successfully removed 0 files from ./val_deslanted\n",
      "Successfully removed 0 files from ./val_deslanted/Images\n",
      "Successfully removed 0 files from ./val_deslanted/Labels\n",
      "Successfully removed 0 files from ./val_deslanted/Text\n",
      "Successfully removed 0 files from ./test_deslanted\n",
      "Successfully removed 0 files from ./test_deslanted/Images\n",
      "Successfully removed 0 files from ./test_deslanted/Labels\n",
      "Successfully removed 0 files from ./test_deslanted/Text\n"
     ]
    }
   ],
   "source": [
    "prepare_deslanted_data_files(df_train, source_dir_deslanted, train_destination_dir_deslanted)\n",
    "prepare_deslanted_data_files(df_val, source_dir_deslanted, val_destination_dir_deslanted)\n",
    "prepare_deslanted_data_files(df_test, source_dir_deslanted, test_destination_dir_deslanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
